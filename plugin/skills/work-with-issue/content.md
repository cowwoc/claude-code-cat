# Work With Issue: Direct Phase Orchestration

Execute all work phases (execute, review, merge) with the main agent directly orchestrating each phase.
Shows progress banners at phase transitions while maintaining clean user output.

**Architecture:** This skill is invoked by `/cat:work` after task discovery (Phase 1). The main agent
directly orchestrates all phases:
- Execute: Spawn implementation subagent
- Review: Invoke stakeholder-review skill
- Merge: Spawn merge subagent

This eliminates nested subagent spawning (which is architecturally impossible) and enables proper
skill invocation at the main agent level.

## Arguments Format

The main `/cat:work` skill invokes this with JSON-encoded arguments:

```json
{
  "issue_id": "2.1-issue-name",
  "issue_path": "/workspace/.claude/cat/issues/v2/v2.1/issue-name",
  "worktree_path": "/workspace/.claude/cat/worktrees/2.1-issue-name",
  "branch": "2.1-issue-name",
  "base_branch": "v2.1",
  "estimated_tokens": 45000,
  "trust": "medium",
  "verify": "changed",
  "auto_remove": true
}
```

## Progress Banners

Progress banners for all 4 phases are generated by the work_with_issue_handler and provided
in the SCRIPT OUTPUT PROGRESS BANNERS section. Individual phase banners are also provided
in the INDIVIDUAL PHASE BANNERS section for use at phase transitions.

**If pre-rendered banners are not available** (e.g., after context compaction), skip banner output entirely.
Do NOT manually construct banners or run banner scripts as a fallback.

**Phase symbols:** `○` Pending | `●` Complete | `◉` Active | `✗` Failed

**Banner pattern by phase:**
- Preparing: `◉ ○ ○ ○`
- Executing: `● ◉ ○ ○`
- Reviewing: `● ● ◉ ○`
- Merging: `● ● ● ◉`

---

## Configuration

Extract configuration from arguments:

```bash
# Parse JSON arguments
ISSUE_ID=$(echo "$ARGUMENTS" | jq -r '.issue_id')
ISSUE_PATH=$(echo "$ARGUMENTS" | jq -r '.issue_path')
WORKTREE_PATH=$(echo "$ARGUMENTS" | jq -r '.worktree_path')
BRANCH=$(echo "$ARGUMENTS" | jq -r '.branch')
BASE_BRANCH=$(echo "$ARGUMENTS" | jq -r '.base_branch')
ESTIMATED_TOKENS=$(echo "$ARGUMENTS" | jq -r '.estimated_tokens')
TRUST=$(echo "$ARGUMENTS" | jq -r '.trust')
VERIFY=$(echo "$ARGUMENTS" | jq -r '.verify')
AUTO_REMOVE=$(echo "$ARGUMENTS" | jq -r '.auto_remove')
HAS_EXISTING_WORK=$(echo "$ARGUMENTS" | jq -r '.has_existing_work // false')
EXISTING_COMMITS=$(echo "$ARGUMENTS" | jq -r '.existing_commits // 0')
```

## Step 1: Display Preparing Banner

Display the **Preparing phase** banner from SCRIPT OUTPUT PROGRESS BANNERS (`◉ ○ ○ ○` pattern).

**If SCRIPT OUTPUT PROGRESS BANNERS not found:**
```
FAIL: SCRIPT OUTPUT PROGRESS BANNERS not found.
Handler work_with_issue_handler.py should have provided this via additionalContext.
Check that hooks are properly loaded.
```
Do NOT manually construct output or invoke scripts. Output the error and STOP.

This indicates Phase 1 (prepare) has completed and work phases are starting.

## Step 2: Verify Lock Ownership (M444)

**Before any execution, verify the lock for this issue belongs to the current session.**

```bash
python3 -c "
import json, sys
lock_file = '${CLAUDE_PROJECT_DIR}/.claude/cat/locks/${ISSUE_ID}.lock'
expected = '${CLAUDE_SESSION_ID}'
try:
    with open(lock_file) as f:
        session = json.load(f).get('session_id', '')
    if session == expected:
        print('OK: Lock verified for current session')
    else:
        print(f'ERROR: Lock for ${ISSUE_ID} belongs to session {session}, not {expected}')
        sys.exit(1)
except FileNotFoundError:
    print(f'ERROR: No lock file found for ${ISSUE_ID}. Task was not properly prepared.')
    sys.exit(1)
"
```

If lock ownership verification fails, STOP immediately and return FAILED status. Do NOT proceed
to execution — another session owns this task.

## Step 3: Execute Phase

**Output the Executing banner** from INDIVIDUAL PHASE BANNERS (`● ◉ ○ ○` pattern).

**If INDIVIDUAL PHASE BANNERS not found:**
```
FAIL: INDIVIDUAL PHASE BANNERS not found.
Handler work_with_issue_handler.py should have provided this via additionalContext.
Check that hooks are properly loaded.
```
Do NOT manually construct output or invoke scripts. Output the error and STOP.

### Skip if Resuming

If `HAS_EXISTING_WORK == true`:
- Output: "Resuming task with existing work - skipping to review"
- Skip to Step 4

### Read PLAN.md and Identify Skills

Read the execution steps from PLAN.md to understand what needs to be done:

```bash
# Read PLAN.md execution steps
PLAN_MD="${ISSUE_PATH}/PLAN.md"
EXECUTION_STEPS=$(sed -n '/## Execution Steps/,/^## /p' "$PLAN_MD" | head -n -1)
TASK_GOAL=$(sed -n '/## Goal/,/^## /p' "$PLAN_MD" | head -n -1 | tail -n +2)
```

Scan execution steps for skill references that require spawning capability:

- `/cat:shrink-doc` - Document compression (spawns compare-docs subagent)
- `/cat:compare-docs` - Document equivalence validation (spawns validation subagent)
- `/cat:stakeholder-review` - Code review (spawns reviewer subagents)

**If execution steps reference these skills**, invoke them NOW at the main agent level using the Skill tool.

Example: If PLAN.md says "Step 1: Invoke /cat:shrink-doc on file.md", then:

```
Skill tool:
  skill: "cat:shrink-doc"
  args: "path/to/file.md"
```

**Complete each skill fully before delegation (M440).** Pre-invoked skills may have built-in
iteration loops, validation gates, or multi-step workflows. Run each skill to its documented
completion state before passing results to the implementation subagent. Do NOT pass intermediate
or failed results to the subagent for manual fixing — that bypasses the skill's quality gates.

Capture the output from these skills - the implementation subagent will need the results.

### Delegation Prompt Construction (M455)

**Pass PLAN.md execution steps verbatim without interpretive summarization.**

When constructing the delegation prompt below, include execution steps from PLAN.md exactly as written.
Do NOT add ad-hoc "Important Notes" or aggregate language that might conflict with PLAN.md's structure.

**Why:** If PLAN.md distinguishes Step 2 (path construction) from Step 3 (documentation references),
that distinction is intentional. Adding aggregate language like "Replace ALL occurrences" can prime
the subagent to treat distinct steps as a single operation, causing incomplete execution.

**Pattern:**
- ✅ Include `${EXECUTION_STEPS}` directly from PLAN.md
- ✅ Trust PLAN.md structure - distinct steps should remain distinct
- ❌ Do NOT add interpretive summaries or aggregate instructions
- ❌ Do NOT synthesize "Important Notes" that restate steps differently

### Spawn Implementation Subagent

Spawn a subagent to implement the task:

```
Task tool:
  description: "Execute: implement ${ISSUE_ID}"
  subagent_type: "cat:work-execute"
  model: "sonnet"
  prompt: |
    Execute the implementation for task ${ISSUE_ID}.

    ## Task Configuration
    ISSUE_ID: ${ISSUE_ID}
    ISSUE_PATH: ${ISSUE_PATH}
    WORKTREE_PATH: ${WORKTREE_PATH}
    BRANCH: ${BRANCH}
    BASE_BRANCH: ${BASE_BRANCH}
    ESTIMATED_TOKENS: ${ESTIMATED_TOKENS}
    TRUST_LEVEL: ${TRUST}

    ## Task Goal (from PLAN.md)
    ${TASK_GOAL}

    ## Execution Steps (from PLAN.md)
    ${EXECUTION_STEPS}

    ## Pre-Invoked Skill Results
    [If skills were pre-invoked above, include their output here]

    ## Critical Requirements
    - Work ONLY in the worktree at ${WORKTREE_PATH}
    - Verify you are on branch ${BRANCH} before making changes
    - Follow execution steps from PLAN.md EXACTLY
    - If steps say to invoke a skill that was pre-invoked above, use the provided results
    - Update STATE.md in the SAME commit as implementation (status: closed, progress: 100%)
    - Run tests if applicable
    - Commit your changes with appropriate commit message format

    ## Return Format
    Return JSON when complete:
    ```json
    {
      "status": "SUCCESS|PARTIAL|FAILED|BLOCKED",
      "tokens_used": <actual>,
      "percent_of_context": <actual>,
      "compaction_events": 0,
      "commits": [
        {"hash": "abc123", "message": "feature: description", "type": "feature"}
      ],
      "files_changed": <actual>,
      "task_metrics": {},
      "discovered_issues": [],
      "verification": {
        "build_passed": true,
        "tests_passed": true,
        "test_count": 15
      }
    }
    ```

    If you encounter a blocker, return:
    ```json
    {
      "status": "BLOCKED",
      "message": "Description of blocker",
      "blocker": "What needs to be resolved"
    }
    ```

    CRITICAL: You are the implementation agent - implement directly, do NOT spawn another subagent.
```

### Handle Execution Result

Parse the subagent result:

- **SUCCESS/PARTIAL**: Store metrics, proceed to Step 4
- **FAILED**: Return FAILED status with error details
- **BLOCKED**: Return FAILED with blocker info

## Step 4: Review Phase

**Output the Reviewing banner** from INDIVIDUAL PHASE BANNERS (`● ● ◉ ○` pattern).

**If INDIVIDUAL PHASE BANNERS not found:**
```
FAIL: INDIVIDUAL PHASE BANNERS not found.
Handler work_with_issue_handler.py should have provided this via additionalContext.
Check that hooks are properly loaded.
```
Do NOT manually construct output or invoke scripts. Output the error and STOP.

### Skip Review if Configured

Skip if: `VERIFY == "none"` or `TRUST == "high"`

If skipping, output: "Review skipped (verify: ${VERIFY}, trust: ${TRUST})"

### Invoke Stakeholder Review

**CRITICAL: Invoke stakeholder-review at main agent level** (do NOT delegate to subagent):

```
Skill tool:
  skill: "cat:stakeholder-review"
  args: |
    {
      "issue_id": "${ISSUE_ID}",
      "worktree_path": "${WORKTREE_PATH}",
      "verify_level": "${VERIFY}",
      "commits": ${execution_commits_json}
    }
```

The stakeholder-review skill will spawn its own reviewer subagents and return aggregated results.

### Handle Review Result

Parse review result:

- **REVIEW_PASSED**: Continue to Step 5 (squash and approval)
- **CONCERNS**: Note concerns, continue to Step 5
- **REJECTED**: If trust=medium, return for user decision; else continue to approval gate

**NOTE (M390):** "REVIEW_PASSED" means stakeholder review passed, NOT user approval to merge.
User approval is a SEPARATE gate in Step 6.

## Step 5: Squash Commits Before Review (M446, M450)

**Squash worktree commits by topic into clean, reviewable commits before presenting the approval gate.**

**Rebase onto current base first (M450).** The base branch may have advanced since the worktree was
created (e.g., learning commits, other merges). Rebase ensures squashing only captures task changes:

```bash
git -C ${WORKTREE_PATH} rebase ${BASE_BRANCH}
```

Then use `/cat:git-squash` to consolidate commits:

- All implementation work + STATE.md closure into 1 feature/bugfix commit
- Target: 1 commit (STATE.md belongs with implementation, not in a separate commit)

**CRITICAL: STATE.md file grouping (M076):**
- STATE.md status changes belong IN THE SAME COMMIT as the implementation work
- Do NOT create separate `planning:` or `config:` commits for STATE.md updates
- Commit type should match the implementation work (`feature:`, `bugfix:`, `config:`, etc.)
- Example: `feature: add user authentication` includes STATE.md closure in that commit

This ensures the user reviews clean commit history, not intermediate implementation state.

## Step 6: Approval Gate

**CRITICAL (M390): This step is MANDATORY when trust != "high".**

### If trust == "high"

Skip approval gate. Continue directly to Step 7 (merge).

### If trust == "low" or trust == "medium"

**STOP HERE for user approval.** Do NOT proceed to merge automatically.

Present a summary and ask for approval:

```
Display task goal from PLAN.md
Display execution summary (commits, files changed)
Display review results

AskUserQuestion:
  header: "Approval"
  question: "Ready to merge ${ISSUE_ID}?"
  options:
    - "Approve and merge"
    - "Request changes" (provide feedback)
    - "Abort"
```

**If approved:** Continue to Step 7

**If changes requested:** Return to user with feedback for iteration. Return status:
```json
{
  "status": "CHANGES_REQUESTED",
  "issue_id": "${ISSUE_ID}",
  "feedback": "user feedback text"
}
```

**If aborted:** Clean up and return ABORTED status:
```json
{
  "status": "ABORTED",
  "issue_id": "${ISSUE_ID}",
  "message": "User aborted merge"
}
```

## Step 7: Merge Phase

**Output the Merging banner** from INDIVIDUAL PHASE BANNERS (`● ● ● ◉` pattern).

**If INDIVIDUAL PHASE BANNERS not found:**
```
FAIL: INDIVIDUAL PHASE BANNERS not found.
Handler work_with_issue_handler.py should have provided this via additionalContext.
Check that hooks are properly loaded.
```
Do NOT manually construct output or invoke scripts. Output the error and STOP.

Spawn a merge subagent (haiku model - mechanical operations only):

```
Task tool:
  description: "Merge: squash, merge, cleanup"
  subagent_type: "cat:work-merge"
  model: "haiku"
  prompt: |
    Execute the merge phase for task ${ISSUE_ID}.

    ## Configuration
    SESSION_ID: ${CLAUDE_SESSION_ID}
    ISSUE_ID: ${ISSUE_ID}
    ISSUE_PATH: ${ISSUE_PATH}
    WORKTREE_PATH: ${WORKTREE_PATH}
    BRANCH: ${BRANCH}
    BASE_BRANCH: ${BASE_BRANCH}
    COMMITS: ${commits_json}
    AUTO_REMOVE_WORKTREES: ${AUTO_REMOVE}

    Load and follow: @${CLAUDE_PLUGIN_ROOT}/skills/work-merge/SKILL.md

    Return JSON per the output contract in the skill.
```

### Handle Merge Result

Parse merge result:

- **MERGED**: Continue to Step 8
- **CONFLICT**: Return FAILED with conflict details
- **ERROR**: Return FAILED with error

## Step 8: Return Success

Return summary to the main `/cat:work` skill:

```json
{
  "status": "SUCCESS",
  "issue_id": "${ISSUE_ID}",
  "commits": [...],
  "files_changed": N,
  "tokens_used": N,
  "merged": true
}
```

## Error Handling

If any phase fails:

1. Capture error message and phase name
2. Attempt lock release: `${CLAUDE_PLUGIN_ROOT}/scripts/issue-lock.sh release "${CLAUDE_PROJECT_DIR}" "${ISSUE_ID}"
   "${CLAUDE_SESSION_ID}"`
3. Return FAILED status with actual error details

```json
{
  "status": "FAILED",
  "phase": "execute|review|merge",
  "message": "actual error message",
  "issue_id": "${ISSUE_ID}"
}
```

**NEVER fabricate failure responses.** You must actually attempt the work before reporting failure.

## Success Criteria

- [ ] All phases orchestrated at main agent level
- [ ] Skills requiring spawning (shrink-doc, compare-docs, stakeholder-review) invoked directly
- [ ] Approval gates respected based on trust level
- [ ] Progress banners displayed at phase transitions
- [ ] Lock released on completion or error
- [ ] Results collected and returned as JSON
